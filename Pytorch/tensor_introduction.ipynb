{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3910592f",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "**Tensors are specialized data structure that are very similar to arrays and matrices. In Pytorch, we use tensors to encodde the inputs and outputs.**\n",
    "\n",
    "\n",
    "Tensors are similar to NumPys ndarrays, except that tensors can run on GPUs or other hardwares accelerators.Tensors are also optimzed for automatic differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c06f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393fc077",
   "metadata": {},
   "source": [
    "## Initializing Tensor\n",
    "\n",
    "### Tensors are initializes in two ways\n",
    "1. Directly from data\n",
    "the data types is automaticaly inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc90de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a358319",
   "metadata": {},
   "source": [
    "### From a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661e8dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bf8081",
   "metadata": {},
   "source": [
    "### From other Tensor:\n",
    "\n",
    "The new tensor retains the properties(shape,datatype) of the argument tensor, unless explicitly overidden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5aa4142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor:\n",
      " tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.9131, 0.6141],\n",
      "        [0.0441, 0.1829]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_one = torch.ones_like(x_data)\n",
    "\n",
    "print(f\"Ones Tensor:\\n {x_one}\\n\")\n",
    "\n",
    "x_rand= torch.rand_like(x_data,dtype = torch.float)# overrides the datatype of x_data \n",
    " \n",
    "print(f\"Random Tensor: \\n {x_rand}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3214b697",
   "metadata": {},
   "source": [
    "### with random or constant values\n",
    "\n",
    "Shape is a tuple of tensor dimensions. In the functions the determines of the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "061b1f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      "tensor([[0.6059, 0.4638, 0.2178],\n",
      "        [0.8365, 0.5768, 0.1013]])\n",
      "\n",
      "Ones Tensor: \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "Zeroes Tensor: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeroes_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n{rand_tensor}\\n\")\n",
    "print(f\"Ones Tensor: \\n{ones_tensor}\\n\")\n",
    "print(f\"Zeroes Tensor: \\n{zeroes_tensor}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b02f7b",
   "metadata": {},
   "source": [
    "## Attributes of a Tensor\n",
    "\n",
    "Tensor attributes describle their shape, datatype, and the device on which they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd5a4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor:torch.Size([3, 4])\n",
      "Datatype tensor is stored on torch.float32\n",
      "Device tensor is stored on :cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor:{tensor.shape}\")\n",
    "print(f\"Datatype tensor is stored on {tensor.dtype}\" )\n",
    "print(f\"Device tensor is stored on :{tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f0e60e",
   "metadata": {},
   "source": [
    "### Operations on Tensors\n",
    "\n",
    "over 1200 tensor operates , including arithmetic, linear algebra, matrix manipulation(trasposing, indexing, slicing),\n",
    "sampling.\n",
    "\n",
    "Each of these operations can be run on the CPU and Accelerator such CUDA, MTIa or XPU\n",
    "\n",
    "By default tensors are created on the CPU. We need to explicity move tensors to the accelator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ddba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the current accelerator if available\n",
    "if torch.accelerator.is_available():\n",
    "    tensor = tensor.to(torch.accelerator.current_accelerator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84013f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ebd63ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d7fe190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.6.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: c:\\users\\acer\\anaconda3\\lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: torchaudio, torchvision\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a8f55ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\acer\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\acer\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\acer\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch) (2022.7.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch torchvision torchaudio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4202fd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\acer\\anaconda3\\lib\\site-packages (25.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccf6137",
   "metadata": {},
   "source": [
    "### Standard numpy-like indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a9e76ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column:tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4,4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column:{tensor[:,0]}\")\n",
    "print(f\"Last column: {tensor[...,-1]}\")\n",
    "tensor[:,1]=0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ad962",
   "metadata": {},
   "source": [
    "### Joining tensors\n",
    "\n",
    "You can use torch.cat to cancatenate a sequence of tensors along a given dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae99c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.cat([tensor,tensor,tensor],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f17227e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009f838b",
   "metadata": {},
   "source": [
    "## Arithemetic operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a68b9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@ this compuptes the martix multiplication between two tensors. y1,y2,y3 will have the same value \n",
    "\n",
    "y1 = tensor@tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor,tensor.T,out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f779807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = tensor*tensor\n",
    "z2 =tensor.mul(tensor.T)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "\n",
    "torch.mul(tensor,tensor,out= z3\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f731a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Single-element tensors if you have a one-element tensor, for\n",
    "# aggregating all values of a tensor into in one value, you can  convert it to a pythobn\n",
    "# numerical value using item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa38f5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.) <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg,type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae6aaf1",
   "metadata": {},
   "source": [
    "### In-place operations\n",
    "\n",
    "**Operations that store the result into the operand are called in-place. They are denoted by a _ suffix. for example x.copy_(), x.t_() will change x.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fb9f0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor}\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c390357a",
   "metadata": {},
   "source": [
    "**In-place operations save the memory, but can be problematic when computing derivates because of an immdiate loss of history. Hence,their use is discouraged.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be895d",
   "metadata": {},
   "source": [
    "## Cross conversion from numpy to tensor and vice and versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2945cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98b59060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n,1,out = n)\n",
    "print(f\"t:{t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6606498f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
