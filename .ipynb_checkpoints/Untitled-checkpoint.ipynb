{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7268db0",
   "metadata": {},
   "source": [
    "# ODS NLP Course: seminar 2\n",
    "## LogReg, TFiDf ,  Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33bd309",
   "metadata": {},
   "source": [
    "# [1] Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e417009e",
   "metadata": {},
   "source": [
    "## [1.1] Regression Problem: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee3d24a",
   "metadata": {},
   "source": [
    "### [1.1.1] Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904fc6d9",
   "metadata": {},
   "source": [
    "Let's predict the behavior of a linear function\n",
    "$$y = 2x_1 + 5x_2 - 3$$\n",
    "\n",
    "Linear Equation of Multiple Variables for  ùëò\n",
    " The observation will look like this:\n",
    "$$y^{[k]} = x^{[k]}_1 \\cdot w_1 + \\dots + x^{[k]}_m \\cdot w_m + b$$\n",
    "\n",
    "The same equation in vector form via **dot product**:\n",
    "$$y^{[k]} = {\\bf x}^{[k]} \\cdot {\\bf w} + b$$\n",
    "\n",
    "The same equation in matrix form through **the matrix product**:\n",
    "$$y^{[k]} = X^{[k]}_{[1;\\ m]} \\times W_{[m;\\ 1]} + b$$\n",
    "\n",
    "The same equation when generalized to all  ‚àó\n",
    "  observations, moreover,  ùë°\n",
    "  different targets:\n",
    "$${Y}_{[*;\\ t]} = {X}_{[*;\\ m]} \\times {W}_{[m;\\ t]} + {b}_{[*;\\ t]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8184fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff1a103e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 18.,   8.],\n",
       "        [ -6., -13.],\n",
       "        [  0.,  18.],\n",
       "        [ -2.,   2.],\n",
       "        [-10., -10.],\n",
       "        [  3.,  15.],\n",
       "        [ 19.,   3.],\n",
       "        [-18.,   1.],\n",
       "        [-19.,   3.],\n",
       "        [  9.,  17.],\n",
       "        [-19.,   0.],\n",
       "        [ 12.,  -9.],\n",
       "        [  1.,   4.],\n",
       "        [  6.,   7.],\n",
       "        [ -5.,  -6.],\n",
       "        [-18.,  16.],\n",
       "        [-14.,   0.],\n",
       "        [-12.,  18.],\n",
       "        [ -3., -17.],\n",
       "        [  4.,  -7.]]),\n",
       " array([[ 73.],\n",
       "        [-80.],\n",
       "        [ 87.],\n",
       "        [  3.],\n",
       "        [-73.],\n",
       "        [ 78.],\n",
       "        [ 50.],\n",
       "        [-34.],\n",
       "        [-26.],\n",
       "        [100.],\n",
       "        [-41.],\n",
       "        [-24.],\n",
       "        [ 19.],\n",
       "        [ 44.],\n",
       "        [-43.],\n",
       "        [ 41.],\n",
       "        [-31.],\n",
       "        [ 63.],\n",
       "        [-94.],\n",
       "        [-30.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given parameters\n",
    "W_true = [[2],[5]]\n",
    "b_true = [[-3]]\n",
    "\n",
    "# generated observations\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.randint(low=-20,high=20,size=(20,len(W_true))) + 0.0\n",
    "y = X@W_true+b_true\n",
    "X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1967db26",
   "metadata": {},
   "source": [
    "Let's consider the contribution of the parameter to the specular derivative\n",
    "$$\\frac{\\Delta L}{\\Delta p} ‚âà\n",
    "\\frac{\\partial L}{\\partial p} =\n",
    "\\frac{\\partial L}{\\partial \\bar{y}}\n",
    "\\frac{\\partial \\bar{y}}{\\partial p} =\n",
    "L^{'}_{\\bar{y}} \\cdot \\frac{\\partial \\bar{y}}{\\partial p}\n",
    "$$\n",
    "\n",
    "Accordingly, derivatives of  $ùëè$ and $ùë§_ùëñ$:\n",
    "$$\\begin{align}\n",
    "\\frac{\\partial L}{\\partial b} &= L^{'}_\\bar{y} \\cdot 1 \\\\\n",
    "\\frac{\\partial L}{\\partial w_i} &= L^{'}_{\\bar{y}} \\cdot x_i\n",
    "\\end{align}$$\n",
    "\n",
    "In matrix form, you get:\n",
    "$$\\begin{align}\n",
    "\\frac{\\partial L}{\\partial b}_{[*;\\ t]} &= {L^{'}_\\bar{Y}}_{[*;\\ t]}\\\\\n",
    "\\frac{\\partial L}{\\partial W}_{[m;\\ t]} &= X^T_{[m;\\ *]} \\times {L^{'}_\\bar{Y}}_{[*;\\ t]}\n",
    "\\end{align}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168caba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y = 2.00*x1 + 5.00*x2 + 3.00'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def equation(w=np.array([2, 5]), b=np.array(3)):\n",
    "    return 'y = ' + ' + '.join(f'{w[i].item():.2f}*x{i+1}' for i in range(len(w))) + f' + {b.item():.2f}'\n",
    "equation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a17965",
   "metadata": {},
   "source": [
    "## [1.1.2] NumPy solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec191497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step   1:\ty = 2.90*x1 + 5.65*x2 + 0.04\tloss: 3390.100000\n",
      "step 100:\ty = 2.02*x1 + 4.97*x2 + -1.75\tloss: 1.423337\n",
      "step 200:\ty = 2.01*x1 + 4.99*x2 + -2.49\tloss: 0.236051\n",
      "step 300:\ty = 2.00*x1 + 5.00*x2 + -2.79\tloss: 0.039147\n",
      "step 400:\ty = 2.00*x1 + 5.00*x2 + -2.92\tloss: 0.006492\n",
      "step 500:\ty = 2.00*x1 + 5.00*x2 + -2.97\tloss: 0.001077\n",
      "step 600:\ty = 2.00*x1 + 5.00*x2 + -2.99\tloss: 0.000179\n",
      "step 700:\ty = 2.00*x1 + 5.00*x2 + -2.99\tloss: 0.000030\n",
      "step 800:\ty = 2.00*x1 + 5.00*x2 + -3.00\tloss: 0.000005\n",
      "step 900:\ty = 2.00*x1 + 5.00*x2 + -3.00\tloss: 0.000001\n",
      "step 1000:\ty = 2.00*x1 + 5.00*x2 + -3.00\tloss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "np.random.seed(42)\n",
    "W_true = np.array([[2], [5]])\n",
    "b_true = -3\n",
    "X = np.random.randint(-20, 20, (20, len(W_true))) + 0.0\n",
    "y = X @ W_true + b_true\n",
    "\n",
    "def np_train(X, y, lr=0.005, max_iter=1000):\n",
    "    # –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    W = np.zeros((X.shape[-1], y.shape[-1]))\n",
    "    b = np.zeros((1, y.shape[-1]))\n",
    "\n",
    "    for i in range(1, max_iter+1):\n",
    "        # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏ –æ—à–∏–±–∫–∞\n",
    "        y_pred = X @ W + b\n",
    "        loss = np.sum((y_pred - y) ** 2) / len(y)\n",
    "\n",
    "        # —Ä–∞—Å—á—ë—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤\n",
    "        L_grad = (2/len(y)) * (y_pred - y)\n",
    "        b_grad = np.sum(L_grad)\n",
    "        W_grad = np.sum(X.T @ L_grad, axis=1, keepdims=True)\n",
    "\n",
    "        # —à–∞–≥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞\n",
    "        W -= lr * W_grad\n",
    "        b -= lr * b_grad\n",
    "\n",
    "        # –ø—Ä–æ–≥—Ä–µ—Å—Å\n",
    "        if i == 1 or i % 100 == 0:\n",
    "            print(f\"step {i:3}:\", equation(W, b), f\"loss: {loss.item():.6f}\", sep='\\t')\n",
    "\n",
    "np_train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c40467",
   "metadata": {},
   "source": [
    "### [1.1.3] Torch Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51fc0591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b424ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X).to(torch.float32)\n",
    "y = X@W_true + b_true\n",
    "\n",
    "def torch_train(X,y,lr =0.005,max_iter=1000):\n",
    "    W = torch.zeros(X.shape[1],y.shape[1],requires_grad = True)\n",
    "    b = torch.zeros(y.shape[1],requires_grad = True)\n",
    "    \n",
    "    for i in range(1, max_iter):\n",
    "        \n",
    "        y_pred= X@W+b;\n",
    "        loss = torch.mean((y_pred-y)**2)\n",
    "        \n",
    "        loss.backward()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd8082",
   "metadata": {},
   "source": [
    "\n",
    "### [2.1.2] Precision & Recall\n",
    "\n",
    "The problem may be such that we are only interested in predicting the label<<$+$>>\n",
    "\n",
    "Then two metrics stand out:\n",
    "- **Precision** - accuracy, pinpoint aiming (like grafting)\n",
    "- **Recall** ‚Äì completeness, complete solution to the problem (like an antibiotic)\n",
    "\n",
    "\n",
    "$$Precision = \\frac{TP}{TP+FP} = \\frac{TP}{[y_{pred}^+]} = \\frac{[y_{real}^+==y_{pred}^+] }{[y_{pred}^+]} = \\frac{correctly\\predicted\\ +}{all\\predicted\\ +}$$\n",
    "$$Recall = \\frac{TP}{TP+FN} = \\frac{TP}{[y_{real}^+]} = \\frac{[y_{real}^+==y_{pred}^+] }{[y_{real}^+]} = \\frac{correctly\\ predicted\\ +}{all\\ real\\ +}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d40d046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
